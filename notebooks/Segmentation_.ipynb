{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/mva/dlmi/pneumothorax_segmentation/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"from util import *\\nfrom metric import *\\nfrom params import *\\nfrom imports import *\";\n",
       "                var nbb_formatted_code = \"from util import *\\nfrom metric import *\\nfrom params import *\\nfrom imports import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util import *\n",
    "from metric import *\n",
    "from params import *\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from data.masks import *\\nfrom data.dataset import *\\nfrom data.transforms import *\";\n",
       "                var nbb_formatted_code = \"from data.masks import *\\nfrom data.dataset import *\\nfrom data.transforms import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.masks import *\n",
    "from data.dataset import *\n",
    "from data.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"from training.train import *\\nfrom training.freezing import *\\nfrom training.losses import *\";\n",
       "                var nbb_formatted_code = \"from training.train import *\\nfrom training.freezing import *\\nfrom training.losses import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from training.train import *\n",
    "from training.freezing import *\n",
    "from training.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"from model_zoo.unet import *\";\n",
       "                var nbb_formatted_code = \"from model_zoo.unet import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_zoo.unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available cores : 16\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from tqdm import tqdm_notebook as tqdm\\n\\nsns.set_style(\\\"white\\\")\\nKERNEL_START_TIME = time.time()\\nwarnings.simplefilter(action=\\\"ignore\\\", category=UserWarning)\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\\n# warnings.simplefilter(action='ignore', category=RuntimeWarning)\\nprint(\\\"Number of available cores :\\\", multiprocessing.cpu_count())\";\n",
       "                var nbb_formatted_code = \"from tqdm import tqdm_notebook as tqdm\\n\\nsns.set_style(\\\"white\\\")\\nKERNEL_START_TIME = time.time()\\nwarnings.simplefilter(action=\\\"ignore\\\", category=UserWarning)\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\\n# warnings.simplefilter(action='ignore', category=RuntimeWarning)\\nprint(\\\"Number of available cores :\\\", multiprocessing.cpu_count())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "KERNEL_START_TIME = time.time()\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "print(\"Number of available cores :\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"seed_everything(seed)\";\n",
       "                var nbb_formatted_code = \"seed_everything(seed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"../output/df_train.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"../output/df_train.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/df_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"ratio = 4\";\n",
       "                var nbb_formatted_code = \"ratio = 4\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"sns.countplot(df[\\\"has_pneumothorax\\\"])\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"sns.countplot(df[\\\"has_pneumothorax\\\"])\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[\"has_pneumothorax\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"count_pos = len(df[df[\\\"has_pneumothorax\\\"] == 1])\\ncount_neg = len(df[df[\\\"has_pneumothorax\\\"] == 0])\\n\\nidx_drop = np.random.choice(\\n    df[df[\\\"has_pneumothorax\\\"] == 0].index, count_neg - count_pos, replace=False\\n)\\ndf.drop(idx_drop, inplace=True, axis=0)\";\n",
       "                var nbb_formatted_code = \"count_pos = len(df[df[\\\"has_pneumothorax\\\"] == 1])\\ncount_neg = len(df[df[\\\"has_pneumothorax\\\"] == 0])\\n\\nidx_drop = np.random.choice(\\n    df[df[\\\"has_pneumothorax\\\"] == 0].index, count_neg - count_pos, replace=False\\n)\\ndf.drop(idx_drop, inplace=True, axis=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_pos = len(df[df[\"has_pneumothorax\"] == 1])\n",
    "count_neg = len(df[df[\"has_pneumothorax\"] == 0])\n",
    "\n",
    "idx_drop = np.random.choice(\n",
    "    df[df[\"has_pneumothorax\"] == 0].index, count_neg - count_pos, replace=False\n",
    ")\n",
    "df.drop(idx_drop, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"sns.countplot(df[\\\"has_pneumothorax\\\"])\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"sns.countplot(df[\\\"has_pneumothorax\\\"])\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[\"has_pneumothorax\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def fit_seg(\\n    model,\\n    train_dataset,\\n    val_dataset,\\n    epochs=50,\\n    batch_size=32,\\n    use_aux_clf=True,\\n    acc_steps=1,\\n    lr=1e-3,\\n    min_lr=1e-5,\\n    verbose=1,\\n    use_lovasz=False,\\n):\\n\\n    avg_val_loss = 1000\\n\\n    optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\\n    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=min_lr)\\n\\n    if use_lovasz:\\n        loss_seg = lov_loss\\n    else:\\n        loss_seg = nn.BCEWithLogitsLoss(reduction=\\\"mean\\\")\\n    loss_clf = nn.BCEWithLogitsLoss(reduction=\\\"mean\\\")\\n    loss_clf_w = 0.1\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS\\n    )\\n    val_loader = torch.utils.data.DataLoader(\\n        val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\\n    )\\n\\n    for epoch in range(epochs):\\n        model.train()\\n        avg_loss = 0\\n        start_time = time.time()\\n\\n        scheduler.step()\\n        lr = optimizer.param_groups[-1][\\\"lr\\\"]\\n        optimizer.zero_grad()\\n\\n        for step, (x, mask, y) in enumerate(train_loader):\\n            mask_pred, y_pred = model(x.cuda())\\n\\n            loss = loss_seg(mask_pred, mask.cuda())\\n            if use_aux_clf:\\n                loss += loss_clf(y_pred, y.cuda().float()) * loss_clf_w\\n\\n            loss.backward()\\n            avg_loss += loss.item() / len(train_loader)\\n\\n            if step % acc_steps == 0:\\n                optimizer.step()\\n                optimizer.zero_grad()\\n\\n        model.eval()\\n\\n        avg_val_loss = 0.0\\n        val_dice = 0.0\\n        val_acc = 0.0\\n\\n        with torch.no_grad():\\n            for x, mask, y in val_loader:\\n                mask_pred, y_pred = model(x.cuda())\\n\\n                loss = loss_seg(mask_pred.detach(), mask.cuda())\\n                if use_aux_clf:\\n                    loss += loss_clf(y_pred.detach(), y.cuda().float()) * loss_clf_w\\n\\n                avg_val_loss += loss.item() / len(val_loader)\\n                mask_pred = torch.sigmoid(mask_pred.detach())\\n                y_pred = torch.sigmoid(y_pred.detach())\\n\\n                val_acc += accuracy_score(y_pred.detach().cpu() > 0.5, y) / len(\\n                    val_loader\\n                )\\n                val_dice += dice_th(mask_pred.contiguous().cpu(), mask) / len(\\n                    val_loader\\n                )\\n\\n        elapsed_time = time.time() - start_time\\n\\n        if (epoch + 1) % verbose == 0:\\n            elapsed_time = elapsed_time * verbose\\n            print(\\n                f\\\"Epoch {epoch + 1}/{epochs}   lr={lr:.1e}   t={elapsed_time:.0f}s   loss={avg_loss:.3f}   \\\",\\n                end=\\\"\\\",\\n            )\\n            print(\\n                f\\\"dice={val_dice:.3f}   val_loss={avg_val_loss:.3f}   val_acc={val_acc:.3f}\\\"\\n            )\\n\\n    del mask_pred, y_pred, train_loader, val_loader\\n    torch.cuda.empty_cache()\\n    gc.collect()\";\n",
       "                var nbb_formatted_code = \"def fit_seg(\\n    model,\\n    train_dataset,\\n    val_dataset,\\n    epochs=50,\\n    batch_size=32,\\n    use_aux_clf=True,\\n    acc_steps=1,\\n    lr=1e-3,\\n    min_lr=1e-5,\\n    verbose=1,\\n    use_lovasz=False,\\n):\\n\\n    avg_val_loss = 1000\\n\\n    optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\\n    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=min_lr)\\n\\n    if use_lovasz:\\n        loss_seg = lov_loss\\n    else:\\n        loss_seg = nn.BCEWithLogitsLoss(reduction=\\\"mean\\\")\\n    loss_clf = nn.BCEWithLogitsLoss(reduction=\\\"mean\\\")\\n    loss_clf_w = 0.1\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS\\n    )\\n    val_loader = torch.utils.data.DataLoader(\\n        val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\\n    )\\n\\n    for epoch in range(epochs):\\n        model.train()\\n        avg_loss = 0\\n        start_time = time.time()\\n\\n        scheduler.step()\\n        lr = optimizer.param_groups[-1][\\\"lr\\\"]\\n        optimizer.zero_grad()\\n\\n        for step, (x, mask, y) in enumerate(train_loader):\\n            mask_pred, y_pred = model(x.cuda())\\n\\n            loss = loss_seg(mask_pred, mask.cuda())\\n            if use_aux_clf:\\n                loss += loss_clf(y_pred, y.cuda().float()) * loss_clf_w\\n\\n            loss.backward()\\n            avg_loss += loss.item() / len(train_loader)\\n\\n            if step % acc_steps == 0:\\n                optimizer.step()\\n                optimizer.zero_grad()\\n\\n        model.eval()\\n\\n        avg_val_loss = 0.0\\n        val_dice = 0.0\\n        val_acc = 0.0\\n\\n        with torch.no_grad():\\n            for x, mask, y in val_loader:\\n                mask_pred, y_pred = model(x.cuda())\\n\\n                loss = loss_seg(mask_pred.detach(), mask.cuda())\\n                if use_aux_clf:\\n                    loss += loss_clf(y_pred.detach(), y.cuda().float()) * loss_clf_w\\n\\n                avg_val_loss += loss.item() / len(val_loader)\\n                mask_pred = torch.sigmoid(mask_pred.detach())\\n                y_pred = torch.sigmoid(y_pred.detach())\\n\\n                val_acc += accuracy_score(y_pred.detach().cpu() > 0.5, y) / len(\\n                    val_loader\\n                )\\n                val_dice += dice_th(mask_pred.contiguous().cpu(), mask) / len(\\n                    val_loader\\n                )\\n\\n        elapsed_time = time.time() - start_time\\n\\n        if (epoch + 1) % verbose == 0:\\n            elapsed_time = elapsed_time * verbose\\n            print(\\n                f\\\"Epoch {epoch + 1}/{epochs}   lr={lr:.1e}   t={elapsed_time:.0f}s   loss={avg_loss:.3f}   \\\",\\n                end=\\\"\\\",\\n            )\\n            print(\\n                f\\\"dice={val_dice:.3f}   val_loss={avg_val_loss:.3f}   val_acc={val_acc:.3f}\\\"\\n            )\\n\\n    del mask_pred, y_pred, train_loader, val_loader\\n    torch.cuda.empty_cache()\\n    gc.collect()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fit_seg(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    use_aux_clf=True,\n",
    "    acc_steps=1,\n",
    "    lr=1e-3,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1,\n",
    "    use_lovasz=False,\n",
    "):\n",
    "\n",
    "    avg_val_loss = 1000\n",
    "\n",
    "    optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=min_lr)\n",
    "\n",
    "    if use_lovasz:\n",
    "        loss_seg = lov_loss\n",
    "    else:\n",
    "        loss_seg = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    loss_clf = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    loss_clf_w = 0.1\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        avg_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "        lr = optimizer.param_groups[-1][\"lr\"]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for step, (x, mask, y) in enumerate(train_loader):\n",
    "            mask_pred, y_pred = model(x.cuda())\n",
    "\n",
    "            loss = loss_seg(mask_pred, mask.cuda())\n",
    "            if use_aux_clf:\n",
    "                loss += loss_clf(y_pred, y.cuda().float()) * loss_clf_w\n",
    "\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "            if step % acc_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        avg_val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        val_acc = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, mask, y in val_loader:\n",
    "                mask_pred, y_pred = model(x.cuda())\n",
    "\n",
    "                loss = loss_seg(mask_pred.detach(), mask.cuda())\n",
    "                if use_aux_clf:\n",
    "                    loss += loss_clf(y_pred.detach(), y.cuda().float()) * loss_clf_w\n",
    "\n",
    "                avg_val_loss += loss.item() / len(val_loader)\n",
    "                mask_pred = torch.sigmoid(mask_pred.detach())\n",
    "                y_pred = torch.sigmoid(y_pred.detach())\n",
    "\n",
    "                val_acc += accuracy_score(y_pred.detach().cpu() > 0.5, y) / len(\n",
    "                    val_loader\n",
    "                )\n",
    "                val_dice += dice_th(mask_pred.contiguous().cpu(), mask) / len(\n",
    "                    val_loader\n",
    "                )\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        if (epoch + 1) % verbose == 0:\n",
    "            elapsed_time = elapsed_time * verbose\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{epochs}   lr={lr:.1e}   t={elapsed_time:.0f}s   loss={avg_loss:.3f}   \",\n",
    "                end=\"\",\n",
    "            )\n",
    "            print(\n",
    "                f\"dice={val_dice:.3f}   val_loss={avg_val_loss:.3f}   val_acc={val_acc:.3f}\"\n",
    "            )\n",
    "\n",
    "    del mask_pred, y_pred, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"def model_training(\\n    backbone, df_train, df_val, ratio=4, seed=2020, save=False, **hparams,\\n):\\n    seed_everything(seed)\\n\\n    center_block = \\\"aspp\\\" if hparams[\\\"use_aspp\\\"] else \\\"std\\\"\\n    attention_type = \\\"scse\\\" if hparams[\\\"use_scse\\\"] else None\\n\\n    model = SegmentationUnet(\\n        SETTINGS[backbone],\\n        num_classes=1,\\n        center_block=center_block,\\n        aux_clf=True,\\n        use_hypercolumns=hparams[\\\"use_hypercolumns\\\"],\\n        attention_type=attention_type,\\n    ).cuda()\\n\\n    train_dataset = PneumoDataset(df_train, transforms=get_transfos(), ratio=ratio)\\n    val_dataset = PneumoDataset(df_val, transforms=None, ratio=ratio)\\n\\n    freeze_encoder(model)\\n    n_parameters = count_parameters(model)\\n    print(f\\\"\\\\n - Training with frozen encoder\\\")\\n    print(f\\\"\\\\t -> {n_parameters} trainable parameters\\\\n\\\")\\n\\n    fit_seg(\\n        model,\\n        train_dataset,\\n        val_dataset,\\n        epochs=hparams[\\\"epoch_frozen\\\"],\\n        batch_size=hparams[\\\"batch_size\\\"],\\n        lr=hparams[\\\"lr_frozen\\\"],\\n        min_lr=hparams[\\\"lr_min_frozen\\\"],\\n        use_lovasz=hparams[\\\"use_lovasz\\\"],\\n        use_aux_clf=True,\\n        verbose=1,\\n    )\\n\\n    unfreeze_encoder(model)\\n    n_parameters = count_parameters(model)\\n    print(f\\\"\\\\n - Training full model\\\")\\n    print(f\\\"\\\\t -> {n_parameters} trainable parameters\\\\n\\\")\\n\\n    fit_seg(\\n        model,\\n        train_dataset,\\n        val_dataset,\\n        epochs=hparams[\\\"epoch\\\"],\\n        batch_size=hparams[\\\"batch_size\\\"],\\n        lr=hparams[\\\"lr\\\"],\\n        min_lr=hparams[\\\"lr_min\\\"],\\n        use_aux_clf=True,\\n        verbose=1,\\n    )\\n\\n    if save:\\n        save_model_weights(model, f\\\"unet_{backbone}_{i + 1}_1.pt\\\", verbose=1)\";\n",
       "                var nbb_formatted_code = \"def model_training(\\n    backbone, df_train, df_val, ratio=4, seed=2020, save=False, **hparams,\\n):\\n    seed_everything(seed)\\n\\n    center_block = \\\"aspp\\\" if hparams[\\\"use_aspp\\\"] else \\\"std\\\"\\n    attention_type = \\\"scse\\\" if hparams[\\\"use_scse\\\"] else None\\n\\n    model = SegmentationUnet(\\n        SETTINGS[backbone],\\n        num_classes=1,\\n        center_block=center_block,\\n        aux_clf=True,\\n        use_hypercolumns=hparams[\\\"use_hypercolumns\\\"],\\n        attention_type=attention_type,\\n    ).cuda()\\n\\n    train_dataset = PneumoDataset(df_train, transforms=get_transfos(), ratio=ratio)\\n    val_dataset = PneumoDataset(df_val, transforms=None, ratio=ratio)\\n\\n    freeze_encoder(model)\\n    n_parameters = count_parameters(model)\\n    print(f\\\"\\\\n - Training with frozen encoder\\\")\\n    print(f\\\"\\\\t -> {n_parameters} trainable parameters\\\\n\\\")\\n\\n    fit_seg(\\n        model,\\n        train_dataset,\\n        val_dataset,\\n        epochs=hparams[\\\"epoch_frozen\\\"],\\n        batch_size=hparams[\\\"batch_size\\\"],\\n        lr=hparams[\\\"lr_frozen\\\"],\\n        min_lr=hparams[\\\"lr_min_frozen\\\"],\\n        use_lovasz=hparams[\\\"use_lovasz\\\"],\\n        use_aux_clf=True,\\n        verbose=1,\\n    )\\n\\n    unfreeze_encoder(model)\\n    n_parameters = count_parameters(model)\\n    print(f\\\"\\\\n - Training full model\\\")\\n    print(f\\\"\\\\t -> {n_parameters} trainable parameters\\\\n\\\")\\n\\n    fit_seg(\\n        model,\\n        train_dataset,\\n        val_dataset,\\n        epochs=hparams[\\\"epoch\\\"],\\n        batch_size=hparams[\\\"batch_size\\\"],\\n        lr=hparams[\\\"lr\\\"],\\n        min_lr=hparams[\\\"lr_min\\\"],\\n        use_aux_clf=True,\\n        verbose=1,\\n    )\\n\\n    if save:\\n        save_model_weights(model, f\\\"unet_{backbone}_{i + 1}_1.pt\\\", verbose=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_training(\n",
    "    backbone, df_train, df_val, ratio=4, seed=2020, save=False, **hparams,\n",
    "):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    center_block = \"aspp\" if hparams[\"use_aspp\"] else \"std\"\n",
    "    attention_type = \"scse\" if hparams[\"use_scse\"] else None\n",
    "\n",
    "    model = SegmentationUnet(\n",
    "        SETTINGS[backbone],\n",
    "        num_classes=1,\n",
    "        center_block=center_block,\n",
    "        aux_clf=True,\n",
    "        use_hypercolumns=hparams[\"use_hypercolumns\"],\n",
    "        attention_type=attention_type,\n",
    "    ).cuda()\n",
    "\n",
    "    train_dataset = PneumoDataset(df_train, transforms=get_transfos(), ratio=ratio)\n",
    "    val_dataset = PneumoDataset(df_val, transforms=None, ratio=ratio)\n",
    "\n",
    "    freeze_encoder(model)\n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f\"\\n - Training with frozen encoder\")\n",
    "    print(f\"\\t -> {n_parameters} trainable parameters\\n\")\n",
    "\n",
    "    fit_seg(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        epochs=hparams[\"epoch_frozen\"],\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        lr=hparams[\"lr_frozen\"],\n",
    "        min_lr=hparams[\"lr_min_frozen\"],\n",
    "        use_lovasz=hparams[\"use_lovasz\"],\n",
    "        use_aux_clf=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    unfreeze_encoder(model)\n",
    "    n_parameters = count_parameters(model)\n",
    "    print(f\"\\n - Training full model\")\n",
    "    print(f\"\\t -> {n_parameters} trainable parameters\\n\")\n",
    "\n",
    "    fit_seg(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        epochs=hparams[\"epoch\"],\n",
    "        batch_size=hparams[\"batch_size\"],\n",
    "        lr=hparams[\"lr\"],\n",
    "        min_lr=hparams[\"lr_min\"],\n",
    "        use_aux_clf=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    if save:\n",
    "        save_model_weights(model, f\"unet_{backbone}_{i + 1}_1.pt\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"backbone = \\\"resnet34\\\"\";\n",
       "                var nbb_formatted_code = \"backbone = \\\"resnet34\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backbone = \"resnet34\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"y = df[\\\"has_pneumothorax\\\"].values\";\n",
       "                var nbb_formatted_code = \"y = df[\\\"has_pneumothorax\\\"].values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df[\"has_pneumothorax\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"splits = list(StratifiedKFold(n_splits=2, shuffle=True, random_state=seed).split(y, y))\\ntrain_idx, val_idx = splits[0]\";\n",
       "                var nbb_formatted_code = \"splits = list(StratifiedKFold(n_splits=2, shuffle=True, random_state=seed).split(y, y))\\ntrain_idx, val_idx = splits[0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits = list(StratifiedKFold(n_splits=2, shuffle=True, random_state=seed).split(y, y))\n",
    "train_idx, val_idx = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"df_train = df.iloc[train_idx]\\ndf_val = df.iloc[val_idx]\";\n",
       "                var nbb_formatted_code = \"df_train = df.iloc[train_idx]\\ndf_val = df.iloc[val_idx]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df.iloc[train_idx]\n",
    "df_val = df.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"train_dataset = PneumoDataset(df_train, transforms=get_transfos(), ratio=ratio)\\nval_dataset = PneumoDataset(df_val, transforms=None, ratio=ratio)\";\n",
       "                var nbb_formatted_code = \"train_dataset = PneumoDataset(df_train, transforms=get_transfos(), ratio=ratio)\\nval_dataset = PneumoDataset(df_val, transforms=None, ratio=ratio)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = PneumoDataset(df_train, transforms=get_transfos(), ratio=ratio)\n",
    "val_dataset = PneumoDataset(df_val, transforms=None, ratio=ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 10,\\n    \\\"epoch\\\": 20,\\n    \\\"lr\\\": 1e-4,\\n    \\\"lr_min\\\": 1e-5,\\n    \\\"use_lovasz\\\": True,\\n    \\\"use_hypercolumns\\\": False,\\n    \\\"use_aspp\\\": False,\\n    \\\"use_scse\\\": False,\\n}\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 10,\\n    \\\"epoch\\\": 20,\\n    \\\"lr\\\": 1e-4,\\n    \\\"lr_min\\\": 1e-5,\\n    \\\"use_lovasz\\\": True,\\n    \\\"use_hypercolumns\\\": False,\\n    \\\"use_aspp\\\": False,\\n    \\\"use_scse\\\": False,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 10,\n",
    "    \"epoch\": 20,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_min\": 1e-5,\n",
    "    \"use_lovasz\": True,\n",
    "    \"use_hypercolumns\": False,\n",
    "    \"use_aspp\": False,\n",
    "    \"use_scse\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder\n",
      "\t -> 5378178 trainable parameters\n",
      "\n",
      "Epoch 1/10   lr=9.8e-04   t=27s   loss=3.804   dice=0.430   val_loss=1.556   val_acc=0.667\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"Training on GPU is mandatory\"\n",
    "\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning LR/ epochs**\n",
    "\n",
    "1e-3 / 1e-4 / 5 / 10 : acc=0.862, dice=0.779\n",
    "1e-3 / 1e-4 / 5 / 20 : acc=0.870, dice=0.785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/5   lr=9.1e-04   t=39s   loss=2.057   dice=0.012   val_loss=0.532   val_acc=0.579\n",
      "Epoch 2/5   lr=6.9e-04   t=39s   loss=0.351   dice=0.004   val_loss=0.240   val_acc=0.688\n",
      "Epoch 3/5   lr=4.1e-04   t=39s   loss=0.207   dice=0.013   val_loss=0.181   val_acc=0.699\n",
      "Epoch 4/5   lr=1.9e-04   t=39s   loss=0.169   dice=0.063   val_loss=0.163   val_acc=0.702\n",
      "Epoch 5/5   lr=1.0e-04   t=39s   loss=0.154   dice=0.116   val_loss=0.153   val_acc=0.710\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/20   lr=9.9e-05   t=41s   loss=0.142   dice=0.217   val_loss=0.139   val_acc=0.747\n",
      "Epoch 2/20   lr=9.8e-05   t=41s   loss=0.121   dice=0.397   val_loss=0.126   val_acc=0.768\n",
      "Epoch 3/20   lr=9.5e-05   t=41s   loss=0.099   dice=0.478   val_loss=0.113   val_acc=0.775\n",
      "Epoch 4/20   lr=9.1e-05   t=41s   loss=0.081   dice=0.468   val_loss=0.104   val_acc=0.793\n",
      "Epoch 5/20   lr=8.7e-05   t=41s   loss=0.066   dice=0.494   val_loss=0.098   val_acc=0.772\n",
      "Epoch 6/20   lr=8.1e-05   t=41s   loss=0.057   dice=0.498   val_loss=0.090   val_acc=0.801\n",
      "Epoch 7/20   lr=7.5e-05   t=41s   loss=0.050   dice=0.499   val_loss=0.089   val_acc=0.799\n",
      "Epoch 8/20   lr=6.9e-05   t=41s   loss=0.043   dice=0.501   val_loss=0.088   val_acc=0.801\n",
      "Epoch 9/20   lr=6.2e-05   t=41s   loss=0.039   dice=0.511   val_loss=0.084   val_acc=0.793\n",
      "Epoch 10/20   lr=5.5e-05   t=41s   loss=0.036   dice=0.505   val_loss=0.083   val_acc=0.799\n",
      "Epoch 11/20   lr=4.8e-05   t=41s   loss=0.032   dice=0.522   val_loss=0.082   val_acc=0.797\n",
      "Epoch 12/20   lr=4.1e-05   t=41s   loss=0.030   dice=0.519   val_loss=0.080   val_acc=0.804\n",
      "Epoch 13/20   lr=3.5e-05   t=41s   loss=0.028   dice=0.528   val_loss=0.079   val_acc=0.809\n",
      "Epoch 14/20   lr=2.9e-05   t=41s   loss=0.026   dice=0.527   val_loss=0.078   val_acc=0.808\n",
      "Epoch 15/20   lr=2.3e-05   t=41s   loss=0.025   dice=0.529   val_loss=0.078   val_acc=0.810\n",
      "Epoch 16/20   lr=1.9e-05   t=41s   loss=0.024   dice=0.532   val_loss=0.078   val_acc=0.807\n",
      "Epoch 17/20   lr=1.5e-05   t=41s   loss=0.023   dice=0.531   val_loss=0.076   val_acc=0.814\n",
      "Epoch 18/20   lr=1.2e-05   t=41s   loss=0.023   dice=0.530   val_loss=0.077   val_acc=0.811\n",
      "Epoch 19/20   lr=1.1e-05   t=41s   loss=0.022   dice=0.532   val_loss=0.076   val_acc=0.814\n",
      "Epoch 20/20   lr=1.0e-05   t=41s   loss=0.021   dice=0.533   val_loss=0.076   val_acc=0.817\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 20,\\n    \\\"lr\\\": 1e-4,\\n    \\\"lr_min\\\": 1e-5,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 20,\\n    \\\"lr\\\": 1e-4,\\n    \\\"lr_min\\\": 1e-5,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 5,\n",
    "    \"epoch\": 20,\n",
    "    \"lr\": 1e-4,\n",
    "    \"lr_min\": 1e-5,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/5   lr=9.1e-04   t=39s   loss=2.056   dice=0.012   val_loss=0.533   val_acc=0.581\n",
      "Epoch 2/5   lr=6.9e-04   t=39s   loss=0.351   dice=0.004   val_loss=0.240   val_acc=0.687\n",
      "Epoch 3/5   lr=4.1e-04   t=39s   loss=0.207   dice=0.013   val_loss=0.181   val_acc=0.700\n",
      "Epoch 4/5   lr=1.9e-04   t=39s   loss=0.169   dice=0.063   val_loss=0.163   val_acc=0.703\n",
      "Epoch 5/5   lr=1.0e-04   t=39s   loss=0.154   dice=0.116   val_loss=0.153   val_acc=0.710\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/20   lr=9.9e-04   t=41s   loss=0.127   dice=0.499   val_loss=0.119   val_acc=0.634\n",
      "Epoch 2/20   lr=9.8e-04   t=41s   loss=0.086   dice=0.502   val_loss=0.080   val_acc=0.776\n",
      "Epoch 3/20   lr=9.5e-04   t=41s   loss=0.067   dice=0.481   val_loss=0.079   val_acc=0.753\n",
      "Epoch 4/20   lr=9.1e-04   t=41s   loss=0.059   dice=0.527   val_loss=0.066   val_acc=0.798\n",
      "Epoch 5/20   lr=8.7e-04   t=41s   loss=0.051   dice=0.521   val_loss=0.070   val_acc=0.770\n",
      "Epoch 6/20   lr=8.1e-04   t=41s   loss=0.044   dice=0.538   val_loss=0.088   val_acc=0.727\n",
      "Epoch 7/20   lr=7.5e-04   t=41s   loss=0.040   dice=0.488   val_loss=0.122   val_acc=0.615\n",
      "Epoch 8/20   lr=6.9e-04   t=41s   loss=0.038   dice=0.530   val_loss=0.063   val_acc=0.806\n",
      "Epoch 9/20   lr=6.2e-04   t=41s   loss=0.032   dice=0.514   val_loss=0.066   val_acc=0.801\n",
      "Epoch 10/20   lr=5.5e-04   t=41s   loss=0.028   dice=0.558   val_loss=0.081   val_acc=0.763\n",
      "Epoch 11/20   lr=4.8e-04   t=41s   loss=0.023   dice=0.544   val_loss=0.068   val_acc=0.802\n",
      "Epoch 12/20   lr=4.1e-04   t=41s   loss=0.021   dice=0.566   val_loss=0.060   val_acc=0.822\n",
      "Epoch 13/20   lr=3.5e-04   t=41s   loss=0.018   dice=0.571   val_loss=0.062   val_acc=0.829\n",
      "Epoch 14/20   lr=2.9e-04   t=41s   loss=0.016   dice=0.555   val_loss=0.066   val_acc=0.819\n",
      "Epoch 15/20   lr=2.3e-04   t=41s   loss=0.013   dice=0.577   val_loss=0.063   val_acc=0.827\n",
      "Epoch 16/20   lr=1.9e-04   t=41s   loss=0.012   dice=0.581   val_loss=0.066   val_acc=0.823\n",
      "Epoch 17/20   lr=1.5e-04   t=41s   loss=0.011   dice=0.594   val_loss=0.063   val_acc=0.840\n",
      "Epoch 18/20   lr=1.2e-04   t=41s   loss=0.010   dice=0.587   val_loss=0.065   val_acc=0.834\n",
      "Epoch 19/20   lr=1.1e-04   t=41s   loss=0.010   dice=0.589   val_loss=0.065   val_acc=0.839\n",
      "Epoch 20/20   lr=1.0e-04   t=41s   loss=0.009   dice=0.580   val_loss=0.067   val_acc=0.836\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 20,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 20,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 5,\n",
    "    \"epoch\": 20,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\": 1e-4,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/3   lr=7.8e-04   t=52s   loss=2.246   dice=0.012   val_loss=0.694   val_acc=0.577\n",
      "Epoch 2/3   lr=3.3e-04   t=41s   loss=0.485   dice=0.010   val_loss=0.356   val_acc=0.671\n",
      "Epoch 3/3   lr=1.0e-04   t=39s   loss=0.339   dice=0.008   val_loss=0.305   val_acc=0.684\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/25   lr=1.0e-03   t=42s   loss=0.214   dice=0.271   val_loss=0.148   val_acc=0.751\n",
      "Epoch 2/25   lr=9.9e-04   t=42s   loss=0.121   dice=0.499   val_loss=0.109   val_acc=0.784\n",
      "Epoch 3/25   lr=9.7e-04   t=41s   loss=0.086   dice=0.493   val_loss=0.081   val_acc=0.810\n",
      "Epoch 4/25   lr=9.4e-04   t=41s   loss=0.068   dice=0.481   val_loss=0.089   val_acc=0.679\n",
      "Epoch 5/25   lr=9.1e-04   t=41s   loss=0.060   dice=0.525   val_loss=0.074   val_acc=0.792\n",
      "Epoch 6/25   lr=8.8e-04   t=41s   loss=0.053   dice=0.507   val_loss=0.075   val_acc=0.760\n",
      "Epoch 7/25   lr=8.4e-04   t=42s   loss=0.049   dice=0.380   val_loss=0.077   val_acc=0.746\n",
      "Epoch 8/25   lr=7.9e-04   t=44s   loss=0.043   dice=0.544   val_loss=0.064   val_acc=0.803\n",
      "Epoch 9/25   lr=7.4e-04   t=45s   loss=0.039   dice=0.522   val_loss=0.068   val_acc=0.788\n",
      "Epoch 10/25   lr=6.9e-04   t=44s   loss=0.033   dice=0.546   val_loss=0.066   val_acc=0.819\n",
      "Epoch 11/25   lr=6.3e-04   t=42s   loss=0.033   dice=0.562   val_loss=0.072   val_acc=0.792\n",
      "Epoch 12/25   lr=5.8e-04   t=42s   loss=0.028   dice=0.456   val_loss=0.080   val_acc=0.766\n",
      "Epoch 13/25   lr=5.2e-04   t=42s   loss=0.027   dice=0.561   val_loss=0.070   val_acc=0.794\n",
      "Epoch 14/25   lr=4.7e-04   t=42s   loss=0.023   dice=0.561   val_loss=0.080   val_acc=0.773\n",
      "Epoch 15/25   lr=4.1e-04   t=43s   loss=0.019   dice=0.530   val_loss=0.085   val_acc=0.778\n",
      "Epoch 16/25   lr=3.6e-04   t=44s   loss=0.018   dice=0.527   val_loss=0.066   val_acc=0.819\n",
      "Epoch 17/25   lr=3.1e-04   t=42s   loss=0.016   dice=0.568   val_loss=0.062   val_acc=0.831\n",
      "Epoch 18/25   lr=2.6e-04   t=44s   loss=0.013   dice=0.573   val_loss=0.068   val_acc=0.829\n",
      "Epoch 19/25   lr=2.2e-04   t=43s   loss=0.013   dice=0.571   val_loss=0.076   val_acc=0.814\n",
      "Epoch 20/25   lr=1.9e-04   t=42s   loss=0.013   dice=0.585   val_loss=0.068   val_acc=0.832\n",
      "Epoch 21/25   lr=1.6e-04   t=43s   loss=0.011   dice=0.580   val_loss=0.070   val_acc=0.832\n",
      "Epoch 22/25   lr=1.3e-04   t=42s   loss=0.010   dice=0.580   val_loss=0.068   val_acc=0.834\n",
      "Epoch 23/25   lr=1.1e-04   t=42s   loss=0.010   dice=0.593   val_loss=0.069   val_acc=0.840\n",
      "Epoch 24/25   lr=1.0e-04   t=42s   loss=0.009   dice=0.588   val_loss=0.071   val_acc=0.839\n",
      "Epoch 25/25   lr=1.0e-04   t=42s   loss=0.009   dice=0.592   val_loss=0.071   val_acc=0.843\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 25,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 25,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 3,\n",
    "    \"epoch\": 25,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\": 1e-4,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/5   lr=9.1e-04   t=40s   loss=2.071   dice=0.013   val_loss=0.554   val_acc=0.603\n",
      "Epoch 2/5   lr=6.9e-04   t=40s   loss=0.351   dice=0.004   val_loss=0.238   val_acc=0.691\n",
      "Epoch 3/5   lr=4.1e-04   t=40s   loss=0.210   dice=0.017   val_loss=0.180   val_acc=0.690\n",
      "Epoch 4/5   lr=1.9e-04   t=40s   loss=0.168   dice=0.076   val_loss=0.163   val_acc=0.719\n",
      "Epoch 5/5   lr=1.0e-04   t=40s   loss=0.153   dice=0.125   val_loss=0.152   val_acc=0.716\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/40   lr=1.0e-03   t=42s   loss=0.124   dice=0.494   val_loss=0.102   val_acc=0.727\n",
      "Epoch 2/40   lr=9.9e-04   t=42s   loss=0.086   dice=0.387   val_loss=0.092   val_acc=0.692\n",
      "Epoch 3/40   lr=9.9e-04   t=42s   loss=0.066   dice=0.517   val_loss=0.073   val_acc=0.792\n",
      "Epoch 4/40   lr=9.8e-04   t=43s   loss=0.057   dice=0.457   val_loss=0.084   val_acc=0.682\n",
      "Epoch 5/40   lr=9.7e-04   t=42s   loss=0.053   dice=0.504   val_loss=0.071   val_acc=0.777\n",
      "Epoch 6/40   lr=9.5e-04   t=42s   loss=0.052   dice=0.534   val_loss=0.109   val_acc=0.649\n",
      "Epoch 7/40   lr=9.3e-04   t=45s   loss=0.046   dice=0.511   val_loss=0.068   val_acc=0.769\n",
      "Epoch 8/40   lr=9.1e-04   t=44s   loss=0.041   dice=0.541   val_loss=0.061   val_acc=0.810\n",
      "Epoch 9/40   lr=8.9e-04   t=44s   loss=0.039   dice=0.512   val_loss=0.069   val_acc=0.776\n",
      "Epoch 10/40   lr=8.7e-04   t=44s   loss=0.037   dice=0.408   val_loss=0.075   val_acc=0.749\n",
      "Epoch 11/40   lr=8.4e-04   t=44s   loss=0.034   dice=0.534   val_loss=0.071   val_acc=0.781\n",
      "Epoch 12/40   lr=8.1e-04   t=44s   loss=0.034   dice=0.526   val_loss=0.072   val_acc=0.768\n",
      "Epoch 13/40   lr=7.9e-04   t=44s   loss=0.028   dice=0.498   val_loss=0.066   val_acc=0.800\n",
      "Epoch 14/40   lr=7.5e-04   t=44s   loss=0.026   dice=0.503   val_loss=0.133   val_acc=0.650\n",
      "Epoch 15/40   lr=7.2e-04   t=44s   loss=0.026   dice=0.550   val_loss=0.070   val_acc=0.788\n",
      "Epoch 16/40   lr=6.9e-04   t=44s   loss=0.020   dice=0.522   val_loss=0.074   val_acc=0.790\n",
      "Epoch 17/40   lr=6.6e-04   t=44s   loss=0.021   dice=0.487   val_loss=0.090   val_acc=0.780\n",
      "Epoch 18/40   lr=6.2e-04   t=44s   loss=0.022   dice=0.401   val_loss=0.091   val_acc=0.737\n",
      "Epoch 19/40   lr=5.9e-04   t=47s   loss=0.018   dice=0.537   val_loss=0.091   val_acc=0.766\n",
      "Epoch 20/40   lr=5.5e-04   t=45s   loss=0.016   dice=0.550   val_loss=0.080   val_acc=0.779\n",
      "Epoch 21/40   lr=5.1e-04   t=45s   loss=0.016   dice=0.552   val_loss=0.095   val_acc=0.761\n",
      "Epoch 22/40   lr=4.8e-04   t=46s   loss=0.013   dice=0.548   val_loss=0.069   val_acc=0.814\n",
      "Epoch 23/40   lr=4.4e-04   t=45s   loss=0.013   dice=0.560   val_loss=0.075   val_acc=0.813\n",
      "Epoch 24/40   lr=4.1e-04   t=45s   loss=0.013   dice=0.516   val_loss=0.077   val_acc=0.802\n",
      "Epoch 25/40   lr=3.8e-04   t=45s   loss=0.012   dice=0.565   val_loss=0.073   val_acc=0.819\n",
      "Epoch 26/40   lr=3.5e-04   t=45s   loss=0.010   dice=0.580   val_loss=0.076   val_acc=0.819\n",
      "Epoch 27/40   lr=3.1e-04   t=44s   loss=0.009   dice=0.555   val_loss=0.075   val_acc=0.825\n",
      "Epoch 28/40   lr=2.9e-04   t=44s   loss=0.009   dice=0.578   val_loss=0.083   val_acc=0.808\n",
      "Epoch 29/40   lr=2.6e-04   t=45s   loss=0.008   dice=0.587   val_loss=0.077   val_acc=0.834\n",
      "Epoch 30/40   lr=2.3e-04   t=46s   loss=0.008   dice=0.574   val_loss=0.076   val_acc=0.830\n",
      "Epoch 31/40   lr=2.1e-04   t=46s   loss=0.007   dice=0.568   val_loss=0.077   val_acc=0.832\n",
      "Epoch 32/40   lr=1.9e-04   t=45s   loss=0.007   dice=0.556   val_loss=0.081   val_acc=0.815\n",
      "Epoch 33/40   lr=1.7e-04   t=45s   loss=0.007   dice=0.564   val_loss=0.079   val_acc=0.834\n",
      "Epoch 34/40   lr=1.5e-04   t=43s   loss=0.007   dice=0.589   val_loss=0.087   val_acc=0.815\n",
      "Epoch 35/40   lr=1.3e-04   t=44s   loss=0.006   dice=0.580   val_loss=0.079   val_acc=0.837\n",
      "Epoch 36/40   lr=1.2e-04   t=45s   loss=0.006   dice=0.571   val_loss=0.081   val_acc=0.833\n",
      "Epoch 37/40   lr=1.1e-04   t=44s   loss=0.006   dice=0.580   val_loss=0.082   val_acc=0.832\n",
      "Epoch 38/40   lr=1.1e-04   t=43s   loss=0.006   dice=0.576   val_loss=0.081   val_acc=0.833\n",
      "Epoch 39/40   lr=1.0e-04   t=43s   loss=0.006   dice=0.577   val_loss=0.082   val_acc=0.834\n",
      "Epoch 40/40   lr=1.0e-04   t=42s   loss=0.005   dice=0.565   val_loss=0.083   val_acc=0.834\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 40,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 40,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 5,\n",
    "    \"epoch\": 40,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\": 1e-4,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/3   lr=7.8e-04   t=40s   loss=2.246   dice=0.012   val_loss=0.694   val_acc=0.577\n",
      "Epoch 2/3   lr=3.3e-04   t=41s   loss=0.485   dice=0.010   val_loss=0.356   val_acc=0.670\n",
      "Epoch 3/3   lr=1.0e-04   t=41s   loss=0.339   dice=0.008   val_loss=0.305   val_acc=0.681\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/25   lr=1.0e-03   t=45s   loss=0.214   dice=0.175   val_loss=0.149   val_acc=0.699\n",
      "Epoch 2/25   lr=9.8e-04   t=43s   loss=0.119   dice=0.474   val_loss=0.102   val_acc=0.767\n",
      "Epoch 3/25   lr=9.7e-04   t=42s   loss=0.084   dice=0.493   val_loss=0.080   val_acc=0.799\n",
      "Epoch 4/25   lr=9.4e-04   t=43s   loss=0.068   dice=0.370   val_loss=0.095   val_acc=0.641\n",
      "Epoch 5/25   lr=9.1e-04   t=43s   loss=0.059   dice=0.427   val_loss=0.105   val_acc=0.550\n",
      "Epoch 6/25   lr=8.7e-04   t=42s   loss=0.051   dice=0.488   val_loss=0.083   val_acc=0.707\n",
      "Epoch 7/25   lr=8.2e-04   t=42s   loss=0.046   dice=0.503   val_loss=0.068   val_acc=0.799\n",
      "Epoch 8/25   lr=7.7e-04   t=42s   loss=0.043   dice=0.552   val_loss=0.069   val_acc=0.772\n",
      "Epoch 9/25   lr=7.2e-04   t=44s   loss=0.037   dice=0.537   val_loss=0.086   val_acc=0.724\n",
      "Epoch 10/25   lr=6.6e-04   t=42s   loss=0.035   dice=0.475   val_loss=0.067   val_acc=0.802\n",
      "Epoch 11/25   lr=6.0e-04   t=42s   loss=0.031   dice=0.555   val_loss=0.072   val_acc=0.771\n",
      "Epoch 12/25   lr=5.4e-04   t=42s   loss=0.026   dice=0.512   val_loss=0.076   val_acc=0.780\n",
      "Epoch 13/25   lr=4.7e-04   t=42s   loss=0.024   dice=0.558   val_loss=0.076   val_acc=0.775\n",
      "Epoch 14/25   lr=4.1e-04   t=42s   loss=0.022   dice=0.553   val_loss=0.064   val_acc=0.820\n",
      "Epoch 15/25   lr=3.5e-04   t=42s   loss=0.018   dice=0.530   val_loss=0.066   val_acc=0.812\n",
      "Epoch 16/25   lr=2.9e-04   t=42s   loss=0.016   dice=0.544   val_loss=0.072   val_acc=0.810\n",
      "Epoch 17/25   lr=2.4e-04   t=43s   loss=0.014   dice=0.559   val_loss=0.066   val_acc=0.839\n",
      "Epoch 18/25   lr=1.9e-04   t=42s   loss=0.012   dice=0.572   val_loss=0.068   val_acc=0.835\n",
      "Epoch 19/25   lr=1.4e-04   t=42s   loss=0.012   dice=0.575   val_loss=0.072   val_acc=0.822\n",
      "Epoch 20/25   lr=1.0e-04   t=43s   loss=0.011   dice=0.585   val_loss=0.067   val_acc=0.838\n",
      "Epoch 21/25   lr=7.1e-05   t=43s   loss=0.010   dice=0.575   val_loss=0.067   val_acc=0.839\n",
      "Epoch 22/25   lr=4.5e-05   t=42s   loss=0.010   dice=0.577   val_loss=0.067   val_acc=0.841\n",
      "Epoch 23/25   lr=2.6e-05   t=42s   loss=0.010   dice=0.582   val_loss=0.068   val_acc=0.839\n",
      "Epoch 24/25   lr=1.4e-05   t=42s   loss=0.010   dice=0.578   val_loss=0.069   val_acc=0.838\n",
      "Epoch 25/25   lr=1.0e-05   t=43s   loss=0.010   dice=0.578   val_loss=0.068   val_acc=0.843\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 25,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-5,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 25,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 1e-5,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 3,\n",
    "    \"epoch\": 25,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\": 1e-5,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/3   lr=4.0e-04   t=41s   loss=2.953   dice=0.012   val_loss=1.716   val_acc=0.556\n",
      "Epoch 2/3   lr=2.0e-04   t=41s   loss=0.945   dice=0.011   val_loss=0.625   val_acc=0.627\n",
      "Epoch 3/3   lr=1.0e-04   t=41s   loss=0.580   dice=0.012   val_loss=0.483   val_acc=0.654\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/25   lr=5.0e-04   t=42s   loss=0.358   dice=0.001   val_loss=0.265   val_acc=0.746\n",
      "Epoch 2/25   lr=4.9e-04   t=42s   loss=0.211   dice=0.151   val_loss=0.177   val_acc=0.775\n",
      "Epoch 3/25   lr=4.9e-04   t=42s   loss=0.138   dice=0.424   val_loss=0.131   val_acc=0.743\n",
      "Epoch 4/25   lr=4.8e-04   t=42s   loss=0.101   dice=0.495   val_loss=0.105   val_acc=0.778\n",
      "Epoch 5/25   lr=4.6e-04   t=42s   loss=0.079   dice=0.499   val_loss=0.091   val_acc=0.788\n",
      "Epoch 6/25   lr=4.5e-04   t=42s   loss=0.064   dice=0.506   val_loss=0.088   val_acc=0.734\n",
      "Epoch 7/25   lr=4.3e-04   t=42s   loss=0.052   dice=0.513   val_loss=0.076   val_acc=0.791\n",
      "Epoch 8/25   lr=4.1e-04   t=44s   loss=0.047   dice=0.529   val_loss=0.074   val_acc=0.794\n",
      "Epoch 9/25   lr=3.9e-04   t=45s   loss=0.038   dice=0.533   val_loss=0.069   val_acc=0.824\n",
      "Epoch 10/25   lr=3.6e-04   t=43s   loss=0.037   dice=0.487   val_loss=0.080   val_acc=0.793\n",
      "Epoch 11/25   lr=3.4e-04   t=43s   loss=0.032   dice=0.551   val_loss=0.068   val_acc=0.822\n",
      "Epoch 12/25   lr=3.1e-04   t=43s   loss=0.029   dice=0.548   val_loss=0.084   val_acc=0.768\n",
      "Epoch 13/25   lr=2.9e-04   t=42s   loss=0.026   dice=0.563   val_loss=0.064   val_acc=0.834\n",
      "Epoch 14/25   lr=2.6e-04   t=42s   loss=0.024   dice=0.532   val_loss=0.066   val_acc=0.807\n",
      "Epoch 15/25   lr=2.4e-04   t=42s   loss=0.021   dice=0.565   val_loss=0.069   val_acc=0.814\n",
      "Epoch 16/25   lr=2.1e-04   t=42s   loss=0.020   dice=0.552   val_loss=0.066   val_acc=0.822\n",
      "Epoch 17/25   lr=1.9e-04   t=43s   loss=0.017   dice=0.572   val_loss=0.064   val_acc=0.840\n",
      "Epoch 18/25   lr=1.7e-04   t=42s   loss=0.015   dice=0.585   val_loss=0.062   val_acc=0.840\n",
      "Epoch 19/25   lr=1.5e-04   t=42s   loss=0.015   dice=0.578   val_loss=0.067   val_acc=0.827\n",
      "Epoch 20/25   lr=1.4e-04   t=42s   loss=0.014   dice=0.571   val_loss=0.067   val_acc=0.836\n",
      "Epoch 21/25   lr=1.2e-04   t=42s   loss=0.012   dice=0.554   val_loss=0.064   val_acc=0.846\n",
      "Epoch 22/25   lr=1.1e-04   t=42s   loss=0.012   dice=0.589   val_loss=0.065   val_acc=0.844\n",
      "Epoch 23/25   lr=1.1e-04   t=42s   loss=0.011   dice=0.582   val_loss=0.067   val_acc=0.837\n",
      "Epoch 24/25   lr=1.0e-04   t=42s   loss=0.011   dice=0.583   val_loss=0.066   val_acc=0.843\n",
      "Epoch 25/25   lr=1.0e-04   t=42s   loss=0.011   dice=0.576   val_loss=0.065   val_acc=0.848\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 0.5*1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 25,\\n    \\\"lr\\\": 0.5*1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 0.5 * 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 25,\\n    \\\"lr\\\": 0.5 * 1e-3,\\n    \\\"lr_min\\\": 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 0.5 * 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 3,\n",
    "    \"epoch\": 25,\n",
    "    \"lr\": 0.5 * 1e-3,\n",
    "    \"lr_min\": 1e-4,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/5   lr=9.1e-04   t=40s   loss=2.071   dice=0.013   val_loss=0.555   val_acc=0.603\n",
      "Epoch 2/5   lr=6.9e-04   t=40s   loss=0.351   dice=0.004   val_loss=0.238   val_acc=0.692\n",
      "Epoch 3/5   lr=4.1e-04   t=40s   loss=0.210   dice=0.017   val_loss=0.180   val_acc=0.691\n",
      "Epoch 4/5   lr=1.9e-04   t=40s   loss=0.168   dice=0.077   val_loss=0.163   val_acc=0.719\n",
      "Epoch 5/5   lr=1.0e-04   t=40s   loss=0.153   dice=0.125   val_loss=0.152   val_acc=0.715\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/30   lr=1.0e-03   t=42s   loss=0.125   dice=0.369   val_loss=0.099   val_acc=0.768\n",
      "Epoch 2/30   lr=9.9e-04   t=42s   loss=0.085   dice=0.485   val_loss=0.083   val_acc=0.739\n",
      "Epoch 3/30   lr=9.8e-04   t=42s   loss=0.067   dice=0.463   val_loss=0.086   val_acc=0.671\n",
      "Epoch 4/30   lr=9.6e-04   t=42s   loss=0.057   dice=0.473   val_loss=0.073   val_acc=0.775\n",
      "Epoch 5/30   lr=9.3e-04   t=43s   loss=0.052   dice=0.504   val_loss=0.082   val_acc=0.718\n",
      "Epoch 6/30   lr=9.0e-04   t=42s   loss=0.048   dice=0.540   val_loss=0.065   val_acc=0.787\n",
      "Epoch 7/30   lr=8.7e-04   t=42s   loss=0.043   dice=0.538   val_loss=0.073   val_acc=0.759\n",
      "Epoch 8/30   lr=8.4e-04   t=42s   loss=0.040   dice=0.558   val_loss=0.064   val_acc=0.804\n",
      "Epoch 9/30   lr=7.9e-04   t=42s   loss=0.037   dice=0.531   val_loss=0.088   val_acc=0.735\n",
      "Epoch 10/30   lr=7.5e-04   t=43s   loss=0.034   dice=0.505   val_loss=0.064   val_acc=0.806\n",
      "Epoch 11/30   lr=7.0e-04   t=43s   loss=0.029   dice=0.535   val_loss=0.061   val_acc=0.811\n",
      "Epoch 12/30   lr=6.6e-04   t=45s   loss=0.026   dice=0.537   val_loss=0.074   val_acc=0.769\n",
      "Epoch 13/30   lr=6.1e-04   t=43s   loss=0.025   dice=0.534   val_loss=0.102   val_acc=0.707\n",
      "Epoch 14/30   lr=5.5e-04   t=42s   loss=0.023   dice=0.528   val_loss=0.064   val_acc=0.822\n",
      "Epoch 15/30   lr=5.0e-04   t=42s   loss=0.020   dice=0.524   val_loss=0.072   val_acc=0.800\n",
      "Epoch 16/30   lr=4.5e-04   t=42s   loss=0.016   dice=0.542   val_loss=0.067   val_acc=0.821\n",
      "Epoch 17/30   lr=4.0e-04   t=42s   loss=0.017   dice=0.541   val_loss=0.068   val_acc=0.819\n",
      "Epoch 18/30   lr=3.5e-04   t=42s   loss=0.015   dice=0.584   val_loss=0.060   val_acc=0.845\n",
      "Epoch 19/30   lr=3.0e-04   t=42s   loss=0.012   dice=0.566   val_loss=0.066   val_acc=0.831\n",
      "Epoch 20/30   lr=2.5e-04   t=44s   loss=0.011   dice=0.578   val_loss=0.071   val_acc=0.819\n",
      "Epoch 21/30   lr=2.1e-04   t=44s   loss=0.010   dice=0.589   val_loss=0.068   val_acc=0.838\n",
      "Epoch 22/30   lr=1.7e-04   t=42s   loss=0.009   dice=0.575   val_loss=0.067   val_acc=0.841\n",
      "Epoch 23/30   lr=1.3e-04   t=42s   loss=0.009   dice=0.588   val_loss=0.070   val_acc=0.839\n",
      "Epoch 24/30   lr=1.0e-04   t=42s   loss=0.009   dice=0.595   val_loss=0.072   val_acc=0.831\n",
      "Epoch 25/30   lr=7.2e-05   t=42s   loss=0.008   dice=0.594   val_loss=0.069   val_acc=0.840\n",
      "Epoch 26/30   lr=4.8e-05   t=42s   loss=0.008   dice=0.587   val_loss=0.068   val_acc=0.842\n",
      "Epoch 27/30   lr=2.9e-05   t=42s   loss=0.008   dice=0.591   val_loss=0.068   val_acc=0.843\n",
      "Epoch 28/30   lr=1.6e-05   t=42s   loss=0.008   dice=0.592   val_loss=0.069   val_acc=0.842\n",
      "Epoch 29/30   lr=7.7e-06   t=42s   loss=0.008   dice=0.590   val_loss=0.068   val_acc=0.844\n",
      "Epoch 30/30   lr=5.0e-06   t=43s   loss=0.008   dice=0.590   val_loss=0.069   val_acc=0.843\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 30,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 0.5*1e-5,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 5,\\n    \\\"epoch\\\": 30,\\n    \\\"lr\\\": 1e-3,\\n    \\\"lr_min\\\": 0.5 * 1e-5,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 5,\n",
    "    \"epoch\": 30,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\": 0.5 * 1e-5,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Training with frozen encoder \n",
      "\t -> 4920450 trainable parameters\n",
      "\n",
      "Epoch 1/3   lr=4.0e-04   t=42s   loss=2.953   dice=0.012   val_loss=1.718   val_acc=0.558\n",
      "Epoch 2/3   lr=2.0e-04   t=40s   loss=0.945   dice=0.011   val_loss=0.625   val_acc=0.627\n",
      "Epoch 3/3   lr=1.0e-04   t=41s   loss=0.580   dice=0.012   val_loss=0.483   val_acc=0.653\n",
      "\n",
      " - Training full model \n",
      "\t -> 26188098 trainable parameters\n",
      "\n",
      "Epoch 1/40   lr=5.0e-04   t=41s   loss=0.358   dice=0.001   val_loss=0.265   val_acc=0.719\n",
      "Epoch 2/40   lr=5.0e-04   t=42s   loss=0.211   dice=0.189   val_loss=0.184   val_acc=0.678\n",
      "Epoch 3/40   lr=4.9e-04   t=42s   loss=0.139   dice=0.311   val_loss=0.129   val_acc=0.782\n",
      "Epoch 4/40   lr=4.9e-04   t=42s   loss=0.100   dice=0.479   val_loss=0.102   val_acc=0.791\n",
      "Epoch 5/40   lr=4.8e-04   t=42s   loss=0.078   dice=0.498   val_loss=0.095   val_acc=0.751\n",
      "Epoch 6/40   lr=4.8e-04   t=42s   loss=0.064   dice=0.507   val_loss=0.079   val_acc=0.813\n",
      "Epoch 7/40   lr=4.7e-04   t=42s   loss=0.052   dice=0.508   val_loss=0.081   val_acc=0.768\n",
      "Epoch 8/40   lr=4.6e-04   t=42s   loss=0.051   dice=0.539   val_loss=0.085   val_acc=0.733\n",
      "Epoch 9/40   lr=4.5e-04   t=42s   loss=0.039   dice=0.519   val_loss=0.076   val_acc=0.779\n",
      "Epoch 10/40   lr=4.3e-04   t=42s   loss=0.040   dice=0.531   val_loss=0.086   val_acc=0.717\n",
      "Epoch 11/40   lr=4.2e-04   t=42s   loss=0.035   dice=0.439   val_loss=0.083   val_acc=0.775\n",
      "Epoch 12/40   lr=4.1e-04   t=42s   loss=0.031   dice=0.534   val_loss=0.066   val_acc=0.816\n",
      "Epoch 13/40   lr=3.9e-04   t=42s   loss=0.028   dice=0.550   val_loss=0.066   val_acc=0.793\n",
      "Epoch 14/40   lr=3.8e-04   t=42s   loss=0.025   dice=0.514   val_loss=0.071   val_acc=0.781\n",
      "Epoch 15/40   lr=3.6e-04   t=42s   loss=0.024   dice=0.521   val_loss=0.067   val_acc=0.818\n",
      "Epoch 16/40   lr=3.4e-04   t=42s   loss=0.022   dice=0.519   val_loss=0.068   val_acc=0.812\n",
      "Epoch 17/40   lr=3.3e-04   t=42s   loss=0.022   dice=0.536   val_loss=0.065   val_acc=0.824\n",
      "Epoch 18/40   lr=3.1e-04   t=42s   loss=0.022   dice=0.514   val_loss=0.068   val_acc=0.804\n",
      "Epoch 19/40   lr=2.9e-04   t=42s   loss=0.022   dice=0.552   val_loss=0.064   val_acc=0.821\n",
      "Epoch 20/40   lr=2.7e-04   t=42s   loss=0.018   dice=0.519   val_loss=0.070   val_acc=0.800\n",
      "Epoch 21/40   lr=2.6e-04   t=42s   loss=0.016   dice=0.552   val_loss=0.064   val_acc=0.833\n",
      "Epoch 22/40   lr=2.4e-04   t=42s   loss=0.013   dice=0.565   val_loss=0.065   val_acc=0.832\n",
      "Epoch 23/40   lr=2.2e-04   t=42s   loss=0.012   dice=0.581   val_loss=0.067   val_acc=0.836\n",
      "Epoch 24/40   lr=2.1e-04   t=42s   loss=0.011   dice=0.572   val_loss=0.068   val_acc=0.841\n",
      "Epoch 25/40   lr=1.9e-04   t=42s   loss=0.010   dice=0.562   val_loss=0.072   val_acc=0.821\n",
      "Epoch 26/40   lr=1.7e-04   t=43s   loss=0.010   dice=0.579   val_loss=0.071   val_acc=0.836\n",
      "Epoch 27/40   lr=1.6e-04   t=42s   loss=0.009   dice=0.577   val_loss=0.069   val_acc=0.842\n",
      "Epoch 28/40   lr=1.4e-04   t=42s   loss=0.009   dice=0.573   val_loss=0.069   val_acc=0.842\n",
      "Epoch 29/40   lr=1.3e-04   t=42s   loss=0.009   dice=0.595   val_loss=0.078   val_acc=0.829\n",
      "Epoch 30/40   lr=1.2e-04   t=42s   loss=0.009   dice=0.573   val_loss=0.068   val_acc=0.843\n",
      "Epoch 31/40   lr=1.0e-04   t=42s   loss=0.008   dice=0.589   val_loss=0.069   val_acc=0.845\n",
      "Epoch 32/40   lr=9.3e-05   t=42s   loss=0.008   dice=0.582   val_loss=0.069   val_acc=0.840\n",
      "Epoch 33/40   lr=8.3e-05   t=42s   loss=0.007   dice=0.577   val_loss=0.070   val_acc=0.842\n",
      "Epoch 34/40   lr=7.5e-05   t=42s   loss=0.007   dice=0.594   val_loss=0.070   val_acc=0.847\n",
      "Epoch 35/40   lr=6.7e-05   t=42s   loss=0.007   dice=0.583   val_loss=0.071   val_acc=0.845\n",
      "Epoch 36/40   lr=6.1e-05   t=42s   loss=0.007   dice=0.596   val_loss=0.072   val_acc=0.843\n",
      "Epoch 37/40   lr=5.6e-05   t=42s   loss=0.007   dice=0.576   val_loss=0.070   val_acc=0.847\n",
      "Epoch 38/40   lr=5.3e-05   t=42s   loss=0.007   dice=0.584   val_loss=0.071   val_acc=0.844\n",
      "Epoch 39/40   lr=5.1e-05   t=42s   loss=0.006   dice=0.591   val_loss=0.071   val_acc=0.845\n",
      "Epoch 40/40   lr=5.0e-05   t=42s   loss=0.006   dice=0.593   val_loss=0.070   val_acc=0.845\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 0.5 * 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 40,\\n    \\\"lr\\\": 0.5 * 1e-3,\\n    \\\"lr_min\\\": 0.5 * 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_formatted_code = \"hparams = {\\n    \\\"batch_size\\\": 32,\\n    \\\"lr_frozen\\\": 0.5 * 1e-3,\\n    \\\"lr_min_frozen\\\": 1e-4,\\n    \\\"epoch_frozen\\\": 3,\\n    \\\"epoch\\\": 40,\\n    \\\"lr\\\": 0.5 * 1e-3,\\n    \\\"lr_min\\\": 0.5 * 1e-4,\\n}\\nmodel_training(\\n    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr_frozen\": 0.5 * 1e-3,\n",
    "    \"lr_min_frozen\": 1e-4,\n",
    "    \"epoch_frozen\": 3,\n",
    "    \"epoch\": 40,\n",
    "    \"lr\": 0.5 * 1e-3,\n",
    "    \"lr_min\": 0.5 * 1e-4,\n",
    "}\n",
    "model_training(\n",
    "    backbone, df_train, df_val, ratio=ratio, seed=seed, save=False, cp=False, **hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
